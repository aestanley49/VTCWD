## ---------------------------
## This code was written by: a.e. stanley
## For questions: annabelle.stanley@uvm.edu
## Date Created: 2024-09-09
## ---------------------------
## Objective: Model spread of CWD across the NE US
##
## 
## Input:
##    
##
## Output: 
##
##
## ---------------------------

### ### Libraries
library(sf)
library(ggplot2)
library(patchwork)
library(spData)
library(terra)
library(raster)
library(tidyverse)
library(gganimate)
library(gifski)

### To do - 
# set up new sim
## D values set to 0 for vector of hex's with high prop covered by water bodies
## Some linear relationship between slope and D (decreases at higher values)
## Also need to confirm what D value to use 


### Landscape
# Data source - https://www.weather.gov/gis/Counties
US_county_outlines <- st_read(
  "Spread_Diffusion/Data/USCountyOutlines/c_05mr24.shp")

# subset counties (vectors)
NEcounties <- US_county_outlines[US_county_outlines$STATE == "MA" |
                                   US_county_outlines$STATE == "NY" |
                                   US_county_outlines$STATE == "PA" |
                                   US_county_outlines$STATE == "VT" |
                                   US_county_outlines$STATE == "NJ" |
                                   US_county_outlines$STATE == "NH" |
                                   US_county_outlines$STATE == "ME" |
                                   US_county_outlines$STATE == "RI" |
                                   US_county_outlines$STATE == "CT",]

# try and deal with same county name issue
NEcounties$Count_state <- paste0(NEcounties$STATE, NEcounties$COUNTYNAME)

## As one big region (should make below faster..)
# Combine all polygons into one
NE_single_polygon <- st_union(NEcounties)

# Convert the result into an sf object
NE_single_polygon <- st_sf(geometry = NE_single_polygon)

## Set up hex grid
plot(st_make_grid(NEcounties, cellsize = .2, square = FALSE))
plot(NEcounties, add = TRUE)

#https://github.com/r-spatial/sf/issues/1505
# Centroids of hexiods 20km apart
# area = 325
# I checked area of hex grid generated by moving it into ArcPro and calculating the area, look right
hex <- st_make_grid(NEcounties, cellsize = .2, square = FALSE)



# Convert hex grid to an sf object
hex_sf <- st_sf(geometry = hex)

# cut to state boarder.. 

# Assign CRS to hex_sf (assume NEcounties' CRS is correct and use it for hex_sf)
st_crs(hex_sf) <- st_crs(NEcounties)


# Check and fix invalid geometries in hex_sf
hex_sf <- st_make_valid(hex_sf)

# Find intersections between hexagonal grid and NEcounties
NE_hex_grid <- st_intersection(NE_single_polygon, hex_sf) ## This takes forever
# This looks a litte weird because not full hex on edges, but will still work the same


# Plot results
plot(st_geometry(hex_sf), col = 'lightblue', main = 'Intersection of Hex Grid and NEcounties')
plot(st_geometry(NEcounties), add=TRUE, border = 'red')
plot(st_geometry(NE_hex_grid), add = TRUE, col = 'green', border = 'black', lwd = 2)

## Save empty hex grid 
savehex <- NE_hex_grid %>% 
  ggplot() + geom_sf()
ggsave(".\\Spread_Diffusion\\outTWS\\hexgrid.png", width = 4, height = 4)

### ID each cell with number and empty prev 
NE_hex_grid$value <- seq_along(NE_hex_grid$geometry)
NE_hex_grid_df <- as.data.frame(NE_hex_grid$value)
NE_hex_grid_df$prev <- c(0)
NE_hex_grid$prev <- NE_hex_grid_df$prev


### Identify the boundaries 

mymat_adj <- st_intersects(NE_hex_grid, NE_hex_grid)

bordervec <- c()
for(i in 1:nrow(mymat_adj)){
  adj <- (unlist(mymat_adj[i])) 
  if(length(adj) != 7){
    bordervec <- c(bordervec, i)
  }
  
}



NE_bordercells <- NE_hex_grid[bordervec, ]
## Will have to deal with this later - looks kinda wonky but I think it's right

# Probably best going through GIS to ID water body hard boundaries
# # Data sources:
# - https://download.gebco.net/
# - https://hub.arcgis.com/datasets/esri::usa-detailed-water-bodies/about
BoundaryWaters <- st_read(
  "Spread_Diffusion/Data/BoundaryWaters2/BoundaryWaters2.shp")

# Transform BoundaryWaters to match the CRS of NEcounties
BoundaryWaters <- st_transform(BoundaryWaters, st_crs(NEcounties))

BoundaryWaters <- st_make_valid(BoundaryWaters)


plot(NE_hex_grid$geometry)
plot(st_geometry(BoundaryWaters), add = TRUE, col = 'lightblue', border = 'black', lwd = 2)

# Find which polygons in layer1 touch layer2
borders <- st_intersects(NE_hex_grid, BoundaryWaters, sparse = FALSE)
# Get the indices of polygons in NE_hex_grid that border any polygon in BoundaryWaters
hardborder_indices <- which(rowSums(borders) > 0)
# Subset NE_hex_grid to get only the polygons that border BoundaryWaters
hard_borders <- NE_hex_grid[hardborder_indices, ] # can check visually that have lakes and ocean


### Water and slope data pulled together in ArcGIS
# summary was being weird so pulled slope out separately but managed to get it sorted

NEfeatures <- st_read(
  "Spread_Diffusion/Data/hex_grid_waterarea_meanslope/NE_hex_grid_IntersectMATT2.shp")
# Water bodies source - https://www.arcgis.com/home/item.html?id=48c77cbde9a0470fb371f8c8a8a7421a
# Note - filtered so only includes lakes and rivers larger than 2km^2 
slope <- st_read(
  "Spread_Diffusion/Data/hex_grid_slop/NE_hex_grid_1.shp")
# Mean is mean slope value for hex
# Source - Matt sent slope data - from Nature Conservancy, see description in ArcPro Project

# Organize waterarea by hexagon
tryme <- NEfeatures %>% 
  st_drop_geometry(.) %>% 
  group_by(FID_NE_hex, value, Area, FID_1, MEAN) %>% 
  summarise(sumwaterarea = sum(MATTAREA)) %>% 
  ungroup() %>% 
  select(sumwaterarea, value)


NEfeatures_combined <- slope %>%
  left_join(tryme, by = c("value")) %>% 
  select(value, sumwaterarea, MEAN) %>% 
  mutate(sumwaterarea = if_else(is.na(sumwaterarea), 0, sumwaterarea)) %>% 
  mutate(propwater = sumwaterarea/325) # Get proportion covered by water


# Cut off based on prop covered by water
NEfilteredwater <- NEfeatures_combined %>% 
  filter(propwater > .2)

Dropcells_waterID <- NEfilteredwater$value

## Normalize slope mean for each cell (this will be multiplied by D)
# Setting largest to 0
NEfeatures_combined <- NEfeatures_combined %>% 
  mutate(scaled_slope = (MEAN - max(MEAN)) / (min(MEAN) - max(MEAN)))

plot(NE_hex_grid$geometry)
plot(st_geometry(NEfilteredwater), add = TRUE, col = 'lightblue')

## Save water data layer 
savewater <- NE_hex_grid %>% 
  ggplot() + geom_sf() + 
  geom_sf(data = NEfilteredwater, aes(fill = propwater)) + 
  guides(fill="none") + 
  ggtitle("Cells with over 20% covered by water")

ggsave(".\\Spread_Diffusion\\outTWS\\watercellsID.png", width = 4, height = 4)


# Mean/Avg slope (in degrees) for each hexagon
plot(NEfeatures_combined["MEAN"])

## Save slope layer 
saveslope <- NE_hex_grid %>% 
  ggplot() + geom_sf() + 
  geom_sf(data = NEfeatures_combined, aes(fill = MEAN, color = MEAN)) + 
  scale_fill_continuous(name = "Mean % Slope") +
  scale_color_continuous(name = "Mean % Slope")  
#  ggtitle("Average Percent Slope")

ggsave(".\\Spread_Diffusion\\outTWS\\Slopesave.png", width = 4, height = 4)


### Process water layer
# 
# NEwater <- st_read(
#   "Spread_Diffusion/Data/AllNEWater/All_NE_water.shp")
# 
# # Transform NEwater to match the CRS of NEcounties
# NEwater <- st_transform(NEwater, st_crs(NEcounties))
# 
# NEwater <- st_make_valid(NEwater) # takes a minute
# 
# ## Find out what proportion of a hex is covered by water
# # remove boarder cells from consideration
# NO_borders <- NE_hex_grid[-bordervec, ]
# NO_borders <- st_make_valid(NO_borders)
# 
# ## Intersection in R doesn't work so went through GIS 
# # for all other cells, find proportion covered by water (add extra weight to streams?)
# # water_intersect <- st_intersects(NO_borders, NEwater, sparse = FALSE)
# 
# water_intersect <- st_read(
#   "Spread_Diffusion/Data/NEwater_hex_intersect_arcpro/try_water_hex_Intersect.shp")
# 
# water_intersect <- st_make_valid(water_intersect) # takes a minute
# 
# water_intersect_sumbyhex <- as.data.frame(water_intersect) %>% 
#   filter(NAME != "Lake Erie" & NAME != "Lake Ontario") %>% 
#   select(-c(OBJECTID, FID_USA_De, length:Shape_Area, geometry)) %>% 
#   distinct() %>% 
#   group_by(value) %>% 
#   summarise(    SQKM2 = sum(SQKM, na.rm = TRUE), 
#                 SQMI2 = sum(SQMI, na.rm = TRUE)) %>% 
#   mutate(propwater = SQKM2/325)
# 
# cellwater  <- NO_borders %>% full_join(water_intersect_sumbyhex)

### ### I DON"T TRUST THIS. 



## seperate out streams and combine -- 
# There isn't a good way to do this... layer doesn't have streams connected
# NEwater_streams <- NEwater %>%  
#   dplyr::filter(FCODE_DESC == "Stream/River: Hydrographic Category = Perennial" )
# 
# # Check and fix invalid geometries in hex_sf
# NEwater_streams <- st_make_valid(NEwater_streams)
# 
# # Identify touching rivers/streams
# touching_groups <- st_touches(NEwater_streams, sparse = FALSE)
# 
# combined_data <- list()
# 
# # Step 4: Combine features based on touching indices
# for (i in seq_len(nrow(touching_groups))) {
#   touching_indices <- which(touching_groups[i, ])
#   if (length(touching_indices) > 0) {
#     combined_geometry <- st_union(NEwater_streams[touching_indices, ])
#     combined_data[[i]] <- combined_geometry
#   }
# }
# 
# # Step 5: Remove NULL entries
# combined_data <- combined_data[!sapply(combined_data, is.null)]
# 
# # Step 6: Create a new sf object from combined geometries
# combined_data_sf <- st_sf(geometry = do.call(c, combined_data))
# 
# # require squaremiles to be greater than 1
# final_combined_layer2 <-  NEwater_streams %>% filter(SQMI > 3)



### Identify which PA counties have CWD 
# choosing a few to start with, can correct later 

PA_counties_data <- readxl::read_excel("Spread_Diffusion/Data/PACountyPrev_9_8_24.xlsx", col_names = TRUE) # assembled from PA heat map - 7/8/24

PAcounties <- US_county_outlines[US_county_outlines$STATE == "PA",]

### For each county with non zero prevalence.. 
for(i in unique(PA_counties_data$County)){
  ## Pull out the county as a geo subset
  PAsubset_Bedford <- PAcounties[PAcounties$COUNTYNAME == i,]
  #Make it a spatial object and intersect with hex grid
  PAsubset_Bedford <- st_make_valid(PAsubset_Bedford)
  Bed <- st_intersection(PAsubset_Bedford, NE_hex_grid)
  
  # Add prevalence 
  IDcountyprev <- PA_counties_data[PA_counties_data$County == i, 4]
  Bed$prev <- rep(unlist(IDcountyprev), length(Bed$value))
  Bed <- st_make_valid(Bed)
  # Get the area
  Bed$area <- st_area(Bed)
  
  # Differentiate between first object and all others
  if(i == "Bedford"){
    combined <- Bed
  } else{
    # Combine all counties into one dataframe
    combined <- bind_rows(combined, Bed)
  }
  
}





# Ensure combined contains geometry and area
combined <- combined %>%
  mutate(area = as.numeric(st_area(geometry)))  # Ensure area is numeric


# Compute the area of each intersected polygon
combined$area <- st_area(combined)
NE_hex_grid$area <- st_area(NE_hex_grid)

# Compute total area for each hexagon
total_area_df <- NE_hex_grid %>%
  st_set_geometry(NULL) %>%
  group_by(value) %>%
  summarize(total_area = sum(area, na.rm = TRUE), .groups = 'drop') %>% 
  mutate(total_area = as.vector(total_area))

# Calculate proportional area and weighted prevalence
aggregated <- combined %>%
  st_set_geometry(NULL) %>%
  left_join(total_area_df, by = "value") %>%
  mutate(proparea = area / total_area) %>%
  group_by(value) %>%
  summarize(weightedprev = sum(proparea * prev, na.rm = TRUE), .groups = 'drop') %>% 
  mutate(weightedprev = as.vector(weightedprev)) #drop units

# Add the aggregated prevalence to the original hexagonal grid
NE_hex_grid2_starting_prev <- NE_hex_grid %>%
  left_join(aggregated, by = "value") %>%
  mutate(prev = replace_na(weightedprev, 0)) %>%
  select(-weightedprev)

# Optionally, plot the results to check alignment
ggplot() +
  geom_sf(data = NE_hex_grid2_starting_prev, aes(fill = prev)) +
  scale_fill_viridis_c() +
  theme_minimal() +
  labs(title = "Hexagonal Grid with Starting Prevalence Values")
# note - includes all PA data but indiana county has prev of .0014 so data is there but not seeing on my map



### ### ### ID Vermont area 
# Need hex values that are in VT so can trigger simulation to return time step when reaches boarder
VTcounties <- US_county_outlines[US_county_outlines$STATE == "VT",]
# Intersect VT area with hex grid
VTgrid <- st_intersection(VTcounties, NE_hex_grid)
# these are hex values
VermontHexValues <- VTgrid$value





### ### ### ### Run simulation 

### ### Function for disease growth
logistic_reg_closed_func <- function(Nt0, r = .2, K = .4){
  Nt1 <- Nt0 * (1 + (r * (1 - (Nt0/K))))
  # if(Nt1 > .4){
  #   Nt1 <- .4 ## implement cap
  # }
  return(Nt1)
}


### ### Define functions for diffusion.

### ## For regular diffusion 

## amount of disease left in cell..
post_diffusion_func <- function(cellno, mat_prev. = mat_prev, mymat. = mymat, D = .2){ # setting diffusion constant..
  hold <- list()
  adj <- (unlist(mymat.[cellno])) 
  #remove the duplicate cell (if i = 1, remove "1")
  adj <- adj[adj != cellno]
  for(j in adj){
    ## Need to pull concentration out of this.. 
    hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
  }
  outsum <- sum(unlist(hold)) 
  # Can't have negative diffusion
  if(outsum < 0){
    outsum <- 0
  }
  return(outsum * (D/6))
}

### amount to allocate to selected cell
amount_to_allocate_func2 <- function(cellno, mat_prev. = mat_prev, mymat. = mymat, D = .2){
  adj <- (unlist(mymat.[cellno])) 
  #setting diffusion constant..
  hold <- list()
  #remove the duplicate cell (if i = 1, remove "1")
  adj <- adj[adj != cellno]
  for(j in adj){
    ## Need to pull concentration out of this.. 
    hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
  }
  outsum <- sum(unlist(hold), na.rm = TRUE) # will generate NULLS & NAs but that's fine
  # Can't have negative diffusion
  if(outsum < 0){
    outsum <- 0
  }
  post_diffusion_amount <- (outsum * (D/6))
  diff <- mat_prev.[cellno,cellno] - post_diffusion_amount
  if(post_diffusion_amount > mat_prev.[cellno,cellno]){ #guard against negative values
    diff <- 0
  }
  return(diff/length(adj)) ## currently a hard boundary
}

### ## for hard vs soft boundaries (defined in "DiffusionModelMethods.Rmd")

### # Equilibrium (softboundaries)
### Amount to allocate to selected cell (soft)
amount_to_allocate_equilibrium_func <- function(cellno, mat_prev. = mat_prev, mymat. = mymat, D = .2){
  adj <- (unlist(mymat.[cellno])) 
  #remove the duplicate cell (if i = 1, remove "1")
  adj <- adj[adj != cellno]
  #setting diffusion constant..
  if(length(adj) == 6){ ### For all normal (non boundary cells, BAU)
    
    ## Add condition for cells that border boundary cells
    # if there are boundary cells in border, remove them
    includesbounds <- intersect(trackboundarynos, adj)
    if(length(includesbounds) > 0){
      adj <- adj[adj != includesbounds]
    }
    
    hold <- list()
    for(j in adj){
      ## Need to pull concentration out of this.. 
      hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
    }
    outsum <- sum(unlist(hold), na.rm = TRUE) 
    # Can't have negative diffusion
    if(outsum < 0){
      outsum <- 0
    }
    post_diffusion_amount <- (outsum * (D/6))
    diff <- mat_prev.[cellno,cellno] - post_diffusion_amount
    out <- (diff/6) ## soft boundary
    
  } else {   ### For boundary cells
    hold <- list()
    out <- 0 ## prevalence will always be 0 
    
  }
  return(out)
}

### amount to pass on to neighbooring cells (soft)
post_diffusion_equilibrium_func <- function(cellno, mat_prev. = mat_prev, mymat. = mymat, D = .2){ # setting diffusion constant..
  adj <- (unlist(mymat.[cellno])) 
  #remove the duplicate cell (if i = 1, remove "1")
  adj <- adj[adj != cellno]
  ### For all normal (non boundary cells, BAU)
  if(length(adj) == 6){
    
    ## Add condition for cells that border boundary cells
    # if there are boundary cells in border, remove them
    includesbounds <- intersect(trackboundarynos, adj)
    if(length(includesbounds) > 0){
      adj <- adj[adj != includesbounds]
    }
    
    hold <- list()
    for(j in adj){
      ## Need to pull concentration out of this.. 
      hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
    }
    outsum <- sum(unlist(hold)) 
    # Can't have negative diffusion
    if(outsum < 0){
      outsum <- 0
    }
    out <- outsum * (D/6)
  } else {   ### For boundary cells - this amount doesn't matter because cells have dynamic values 
    out <- 0
  }
  
  return(out)
}






### # Hard boundaries - water bodies
### Amount to allocate to selected cell (hard)
amount_to_allocate_hard_func <- function(cellno, mat_prev. = mat_prev, mymat. = mymat, D = .2){
  adj <- (unlist(mymat.[cellno])) 
  #remove the duplicate cell (if i = 1, remove "1")
  adj <- adj[adj != cellno]
  #setting diffusion constant..
  if(length(adj) == 6){ ### For all normal (non boundary cells, BAU)
    
    hold <- list()
    for(j in adj){
      ## Need to pull concentration out of this.. 
      hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
    }
    outsum <- sum(unlist(hold), na.rm = TRUE) 
    # Can't have negative diffusion
    if(outsum < 0){
      outsum <- 0
    }
    post_diffusion_amount <- (outsum * (D/6))
    diff <- mat_prev.[cellno,cellno] - post_diffusion_amount
    out <- (diff/6) ## soft boundary
    
  } else {   ### For boundary cells
    # just going to adjust number of cells divisible by length
    hold <- list()
    for(j in adj){
      ## Need to pull concentration out of this.. 
      hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
    }
    outsum <- sum(unlist(hold), na.rm = TRUE) 
    # Can't have negative diffusion
    if(outsum < 0){
      outsum <- 0
    }
    post_diffusion_amount <- (outsum * (D/(length(adj))))
    diff <- mat_prev.[cellno,cellno] - post_diffusion_amount
    out <- (diff/(length(adj))) ## soft boundary
    
  }
  return(out)
}


### amount to pass on to neighbooring cells (hard)
post_diffusion_hard_func <- function(cellno, mat_prev. = mat_prev, mymat. = mymat, D = .2){ # setting diffusion constant..
  adj <- (unlist(mymat.[cellno])) 
  #remove the duplicate cell (if i = 1, remove "1")
  adj <- adj[adj != cellno]
  ### For all normal (non boundary cells, BAU)
  if(length(adj) == 6){
    
    hold <- list()
    for(j in adj){
      ## Need to pull concentration out of this.. 
      hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
    }
    outsum <- sum(unlist(hold)) 
    # Can't have negative diffusion
    if(outsum < 0){
      outsum <- 0
    }
    out <- outsum * (D/6)
  } else {   ### For boundary cells
    # just going to adjust number of cells divisible by 
    hold <- list()
    for(j in adj){
      ## Need to pull concentration out of this.. 
      hold[j] <- mat_prev.[cellno,cellno] - mat_prev.[j,j]
    }
    outsum <- sum(unlist(hold), na.rm = TRUE) 
    # Can't have negative diffusion
    if(outsum < 0){
      outsum <- 0
    }
    post_diffusion_amount <- (outsum * (D/(length(adj))))
    diff <- mat_prev.[cellno,cellno] - post_diffusion_amount
    out <- (diff/(length(adj))) ## soft boundary
    
  }
  
  return(out)
}




### ### Simulation

# Simulate over 50 years 

### ### ### Set up

# NE_hex_grid2_starting_prev - this is right starting grid

noyears <- 50 # no years 

# Check for NA values
if (any(is.na(NE_hex_grid$value))) {
  stop("NA values detected in the value column.")
}

NE_hex_df <- as.data.frame(cbind(NE_hex_grid2_starting_prev$value, NE_hex_grid2_starting_prev$prev))
names(NE_hex_df) <- c("value", "prev")

### Replicate over as many time steps as needed
og_landscape_list <- replicate(noyears, NE_hex_grid2_starting_prev, simplify = FALSE)

## Need to get adjacency matrix...
mymat_adj <- st_intersects(NE_hex_grid2_starting_prev, NE_hex_grid2_starting_prev)

# Set up matrix to record diffusion 
mat_prev <- matrix(NA, nrow(NE_hex_grid2_starting_prev), nrow(NE_hex_grid2_starting_prev))

mat_prev_list <- replicate((noyears + 1), mat_prev, simplify = FALSE)

### ID cells that are boundary cells and list 
trackboundarynos <- bordervec

### empty vector to hold VT time stamp
VTtimestamp <- c()

## Set D (coefficient of Diffusion) value
Dvalue = 0.02

### ### ### Run over time loop 

for(t in 1:50){
  
  # Grow the disease 
  for(i in 1:nrow(NE_hex_df)){
    if(NE_hex_df[i,2] != 0){
      NE_hex_df[i,2] <- logistic_reg_closed_func(NE_hex_df[i,2])
    }
  }
  
  # set mat prev as diagonal
  diag(mat_prev_list[[t]]) <- NE_hex_df$prev 
  
  for(i in 1:nrow(mat_prev_list[[t]])){
    
    if(!(i %in% trackboundarynos)){ # if the cell is not a boundary cell, normal diffusion
      endprev <- post_diffusion_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
      mat_prev_list[[t+1]][i,i] <- endprev # overwrite prevalence 
      adj <- (unlist(mymat_adj[i]))  
      #remove the duplicate cell (if i = 1, remove "1")
      adj <- adj[adj != i]
      share_prev <- amount_to_allocate_func2(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
      for(n in adj){
        mat_prev_list[[t+1]][i,n] <- share_prev # write in added prevalence
      }
      
    } else{ ## Now do boundary cells.. 
      
      if(!(i %in% hardborder_indices)){ # if the cell is not in the hard boundaires... 
        endprev <- post_diffusion_equilibrium_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        mat_prev_list[[t+1]][i,i] <- endprev # overwrite prevalence 
        adj <- (unlist(mymat_adj[i])) 
        #remove the duplicate cell (if i = 1, remove "1")
        adj <- adj[adj != i]
        share_prev <- amount_to_allocate_equilibrium_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        for(n in adj){
          mat_prev_list[[t+1]][i,n] <- share_prev # write in added prevalence
          
          # if there are boundary cells neighboring target cell
          # needs to give the same amount of prevalence back to cell neighboring boundary cells 
          includesbounds <- intersect(trackboundarynos, n)
          if(length(includesbounds) > 0){
            mat_prev_list[[t+1]][n,i] <- share_prev
          }
        }
        
        
      } else {
        endprev <- post_diffusion_hard_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        mat_prev_list[[t+1]][i,i] <- endprev # overwrite prevalence 
        adj <- (unlist(mymat_adj[i])) 
        #remove the duplicate cell (if i = 1, remove "1")
        adj <- adj[adj != i]
        share_prev <- amount_to_allocate_hard_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        for(n in adj){
          mat_prev_list[[t+1]][i,n] <- share_prev # write in added prevalence
          
        }
        
      } # close else hard boundary 
      
    }
    
  }
  
  ### then sum columns to get new prevalence 
  newprevvales <- colSums(mat_prev_list[[t+1]], na.rm = TRUE)
  
  ### Check to see if the disease is at a detectable level in VT yet
  levelsinVT <- newprevvales[c(VermontHexValues)]
  for(i in levelsinVT){
    if(i > .05){ #if a cell has a value greater than 5%
      if (length(VTtimestamp) == 0){ #only want the first time period it's detected
        VTtimestamp <- t # with current parameters, it's not in VT yet
      }
    }
  }
  
  # For flat earth, would need to change code inside if else statement and add line here setting back to 0
  
  og_landscape_list[[t]]$prev <- NE_hex_df$prev <- newprevvales
  
}


## Pull data into one data frame to set up animation.. 

# Combine data frames into one
combined_df <- do.call(rbind, lapply(seq_along(og_landscape_list), function(i) {
  df <- og_landscape_list[[i]]
  df$year <- i  # Add the index as a new column
  return(df)
}))

# Create the base ggplot object for animations
base_plot <- ggplot() +
  geom_sf(data = og_landscape_list[[50]], aes(fill = prev)) +
  scale_fill_viridis_c(name = "Prevalence") +
  theme_minimal()


ggplot() +
  geom_sf(data = combined_df %>% filter(year == 1), aes(fill = prev)) +
  scale_fill_viridis_c(name = "Prevalence", limits = c(0, .4)) +
  theme_minimal()

# might want to set key to keep standard...

## standard ggplot2
myPlot <- ggplot() +
  geom_sf(data = combined_df, aes(fill = prev)) +
  scale_fill_viridis_c(name = "Prevalence", limits = c(0, .4)) +
  theme_minimal() + 
  # Here comes the gganimate specific bits
  labs(title = 'Year: {frame_time}') +
  transition_time(year) +
  ease_aes('linear')


# Okay so this works.. 
animate(myPlot, renderer = gifski_renderer())

Dvalue

#animate(myPlot, duration = 5, fps = 20, width = 200, height = 200, renderer = gifski_renderer())
anim_save("homogenousD_point2.gif")
### note - haven't duplicated code to make D = .2 and D = .6 visuals, just changed value of D in functions


### Next steps
# Prevalence is getting up to .8 because reset cap happens at beginning of time period
## Has extra disease from diffusion of neighboring cells 
## Can fix it for presentation purposes by resetting any outlies back to .4 
# Check values used in model? 
# Different D depending on: Water bodies? (lakes bigger than x?, topography steeper than y?)
# Or random dispersal events to seed disease elsewhere? 


# objects to use ... 
## Need to see why changing D doesn't do anything first, then can implement
# Values change in methods doc,
# check after first time step that also see different prev values here
# might just be getting too satuated so not seeing much effect of different D
Dropcells_waterID

NEfeatures_combined$scaled_slope


### ### ### Set up

# NE_hex_grid2_starting_prev - this is right starting grid

noyears <- 50 # no years 

# Check for NA values
if (any(is.na(NE_hex_grid$value))) {
  stop("NA values detected in the value column.")
}

NE_hex_df <- as.data.frame(cbind(NE_hex_grid2_starting_prev$value, NE_hex_grid2_starting_prev$prev))
names(NE_hex_df) <- c("value", "prev")

### Replicate over as many time steps as needed
og_landscape_list <- replicate(noyears, NE_hex_grid2_starting_prev, simplify = FALSE)

## Need to get adjacency matrix...
mymat_adj <- st_intersects(NE_hex_grid2_starting_prev, NE_hex_grid2_starting_prev)

# Set up matrix to record diffusion 
mat_prev <- matrix(NA, nrow(NE_hex_grid2_starting_prev), nrow(NE_hex_grid2_starting_prev))

mat_prev_list <- replicate((noyears + 1), mat_prev, simplify = FALSE)

### ID cells that are boundary cells and list 
trackboundarynos <- bordervec

### empty vector to hold VT time stamp
VTtimestamp <- c()

## Set D (coefficient of Diffusion) value
Dvalue = 0.002

### ### ### Run over time loop 

for(t in 1:50){
  
  # Grow the disease 
  for(i in 1:nrow(NE_hex_df)){
    if(NE_hex_df[i,2] != 0){
      NE_hex_df[i,2] <- logistic_reg_closed_func(NE_hex_df[i,2])
    }
  }
  
  # set mat prev as diagonal
  diag(mat_prev_list[[t]]) <- NE_hex_df$prev 
  
  for(i in 1:nrow(mat_prev_list[[t]])){
    
    if(!(i %in% trackboundarynos)){ # if the cell is not a boundary cell, normal diffusion
      endprev <- post_diffusion_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
      mat_prev_list[[t+1]][i,i] <- endprev # overwrite prevalence 
      adj <- (unlist(mymat_adj[i]))  
      #remove the duplicate cell (if i = 1, remove "1")
      adj <- adj[adj != i]
      share_prev <- amount_to_allocate_func2(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
      for(n in adj){
        mat_prev_list[[t+1]][i,n] <- share_prev # write in added prevalence
      }
      
    } else{ ## Now do boundary cells.. 
      
      if(!(i %in% hardborder_indices)){ # if the cell is not in the hard boundaires... 
        endprev <- post_diffusion_equilibrium_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        mat_prev_list[[t+1]][i,i] <- endprev # overwrite prevalence 
        adj <- (unlist(mymat_adj[i])) 
        #remove the duplicate cell (if i = 1, remove "1")
        adj <- adj[adj != i]
        share_prev <- amount_to_allocate_equilibrium_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        for(n in adj){
          mat_prev_list[[t+1]][i,n] <- share_prev # write in added prevalence
          
          # if there are boundary cells neighboring target cell
          # needs to give the same amount of prevalence back to cell neighboring boundary cells 
          includesbounds <- intersect(trackboundarynos, n)
          if(length(includesbounds) > 0){
            mat_prev_list[[t+1]][n,i] <- share_prev
          }
        }
        
        
      } else {
        endprev <- post_diffusion_hard_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        mat_prev_list[[t+1]][i,i] <- endprev # overwrite prevalence 
        adj <- (unlist(mymat_adj[i])) 
        #remove the duplicate cell (if i = 1, remove "1")
        adj <- adj[adj != i]
        share_prev <- amount_to_allocate_hard_func(i, mat_prev_list[[t]], mymat_adj, D = Dvalue)
        for(n in adj){
          mat_prev_list[[t+1]][i,n] <- share_prev # write in added prevalence
          
        }
        
      } # close else hard boundary 
      
    }

  }
  
  ### then sum columns to get new prevalence 
  newprevvales <- colSums(mat_prev_list[[t+1]], na.rm = TRUE)
  
  ### Check to see if the disease is at a detectable level in VT yet
  levelsinVT <- newprevvales[c(VermontHexValues)]
  for(i in levelsinVT){
    if(i > .05){ #if a cell has a value greater than 5%
      if (length(VTtimestamp) == 0){ #only want the first time period it's detected
        VTtimestamp <- t # with current parameters, it's not in VT yet
      }
    }
  }
  
  # For flat earth, would need to change code inside if else statement and add line here setting back to 0
  
  og_landscape_list[[t]]$prev <- NE_hex_df$prev <- newprevvales
  
}






ggplot() +
  geom_sf(data = og_landscape_list[[50]], aes(fill = prev)) +
  scale_fill_viridis_c(name = "Prevalence") +
  theme_minimal()

### Checking get different values of prev for different D.. true but they are very similar..
#point2 <- NE_hex_df
#point4 <- NE_hex_df
