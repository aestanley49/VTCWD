---
title: "Surveillance Handout Workshop"
output: word_document
date: "2024-1-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup2, include=FALSE}
### ### Load libraries 
library(tidyverse)
library(readxl)
library(knitcitations)
library(kableExtra) ## devtools::install_github("kupietz/kableExtra") #some issue needed patching
library(flextable) #kable doesn't knit to word

### ### Read in data
countytbl <- read_excel("Tablesfrom2022DeerHarvestReport.xlsx", sheet = "Table012")
PercentSeason <- read_excel("Tablesfrom2022DeerHarvestReport.xlsx", sheet = "PercentSeason")

### ### Initial cleaning
# Drop extra columns from dataframe 
countytbl <- countytbl %>% dplyr::select(-Total, -HarvestperSqMile)
countytbl_long <- countytbl %>% 
  pivot_longer(cols = !c(County, Town), names_to = "Season", values_to = "Count", values_drop_na = T)

# join percents to main df by Season
fulldf <- countytbl_long %>% full_join(PercentSeason, by = "Season")

## Assume have 1/3 of total from riffle season 
fulldf <- fulldf %>% 
  mutate(Count = case_when(Season == "Regular" ~ Count*1/3, Season != "Regular" ~ Count))

set.seed(123)
fulldf <- fulldf %>%
  add_column(AdultBuckCount = NA, AdultDoeCount = NA, MaleFawnCount = NA, FemaleFawnCount = NA)
for(i in 1:nrow(fulldf)){
  fulldf[i, 9:12] <- t(rmultinom(1, as.numeric(fulldf[i,4]) , prob = fulldf[i,5:8]))
}
```

### The Relationship between prevalence, confidence, and number of samples


The graph below shows the number of samples required to have a 90%, 95%, or 99% confidence (see colored lines) in detecting at least one case of chronic wasting disease, under various assumed prevalences (x-axis). Prevalence refers to the proportion of the diseased population.


```{r genDFs, include= FALSE}
## From this, create 2 different data sets: (aggregated at county level but could do other boundaries)
# 1) All harvested indiviudals
# 2) All sampled inidividuals (just youth and open riffle (which is regular here??))


## Cost points for each sample
# low - Indiana - 16/sample
# High own lab - MI - 189/sample
# High no lab - Ohio - 200/sample

Indiv_county_ALL <- fulldf %>% 
  group_by(County) %>% 
  summarise(AdultBuckCount = sum(AdultBuckCount), 
            AdultDoeCount = sum(AdultDoeCount),
            MaleFawnCount = sum(MaleFawnCount),
            FemaleFawnCount = sum(FemaleFawnCount)) %>% 
  rowwise() %>%
  mutate(ContyTotal = sum(AdultBuckCount, AdultDoeCount, MaleFawnCount, FemaleFawnCount)) %>% 
  mutate(Indiana = 16) %>% 
  mutate(Michigan = 189) %>% 
  mutate(Ohio = 200)

Indiv_county_CheckStations <- fulldf %>% 
  filter(Season == "Youth" | Season == "Regular") %>% 
  group_by(County) %>% 
  summarise(AdultBuckCount = sum(AdultBuckCount), 
            AdultDoeCount = sum(AdultDoeCount),
            MaleFawnCount = sum(MaleFawnCount),
            FemaleFawnCount = sum(FemaleFawnCount)) %>% 
  rowwise() %>%
  mutate(ContyTotal = sum(AdultBuckCount, AdultDoeCount, MaleFawnCount, FemaleFawnCount)) %>% 
  mutate(Indiana = 16) %>% 
  mutate(Michigan = 189) %>% 
  mutate(Ohio = 200)
```

<br>
```{r statewide table, echo=FALSE}
State_ALL <- sum(Indiv_county_ALL$ContyTotal)
State_CheckStations <- sum(Indiv_county_CheckStations$ContyTotal)

SRSno.sampleCalcfunc <- function(prevalence = .01, confidence = .99){
  log(-(confidence - 1))/(log(1 - prevalence))
}

### Create vectors of alpha and prevalence 
#vecalpha <- c(seq(.01, .1, by = .001)) # Change this to select 4 values of alpha that we care about
vecalpha <- c(.01, .05, .1, .2) #99, 95, 90, 80
#vecprev <- c(.001, .01, .1)
vecprev <- c(seq(.01, .1, by = .0001))

All_NoSampSRS <- data.frame()
setcounter <- 1
for(i in vecalpha){
  for(j in vecprev){
    HoldNo <- SRSno.sampleCalcfunc(prevalence = j, confidence = 1 - i)
    IDCharString <- paste0("Alpha_", i, "_", "Prevalence_", j)
    ## Create counter that depends on i & j
    setcounter
    All_NoSampSRS[setcounter, 1] <- IDCharString
    All_NoSampSRS[setcounter, 2] <- HoldNo
    setcounter <- setcounter + 1
  }
}

colnames(All_NoSampSRS) <- c("Surveillance Design", "No. Samples Needed")
All_NoSampSRS$'No. Samples from Check Stations' <- rep(State_CheckStations, nrow(All_NoSampSRS))
All_NoSampSRS$'No. Samples from All Harvest' <- rep(State_ALL, nrow(All_NoSampSRS))
```

```{r, fig.cap="Figure 1. No. Samples Needed under Different Surveillance Designs", echo = F, message=FALSE, fig.width=10, fig.height=7}
All_NoSampSRS_grph_setup <- All_NoSampSRS %>%
  separate_wider_delim(cols = `Surveillance Design`, delim = "_", names = c("alpha_label", "Alpha", "prev_label", "Prevalence")) %>% 
  mutate(Confidence = 1- as.numeric(Alpha)) # Create Confidence
All_NoSampSRS_grph_setup$Prevalence <- as.numeric(All_NoSampSRS_grph_setup$Prevalence)

#ggplot(All_NoSampSRS_grph_setup) + 
#  geom_point(aes(x = Prevalence, y = `No. Samples Needed`, color = Alpha))


## add horizontal line for avg number of checked deer per strata 
ABC <- sum(Indiv_county_CheckStations$AdultBuckCount)
ADC <- sum(Indiv_county_CheckStations$AdultDoeCount)
MFC <- sum(Indiv_county_CheckStations$MaleFawnCount)
FFC <- sum(Indiv_county_CheckStations$FemaleFawnCount)

#create data frame that contains horizontal line location
cutoff <- data.frame(yintercept=ADC, Lines='Adult Doe Count')
cutoff2 <- data.frame(yintercept=MFC, Lines='Male Fawn Count')
cutoff3 <- data.frame(yintercept=FFC, Lines='Female Fawn Count')


ggplot(All_NoSampSRS_grph_setup) + 
  geom_point(aes(x = Prevalence, y = `No. Samples Needed`, color = as.factor(Confidence) ) ) +
  scale_y_continuous(breaks=seq(0, 500,20), limits = c(0, 500) ,
    sec.axis = sec_axis(~ . * 189, name = "Cost (Michigan - 189$/sample)\n") #\n adds line break or space
  ) + 
  #scale_x_continuous(breaks=seq(0, 1, .01)) +
  labs(color = "Confidence") + 
  geom_hline(aes(yintercept=yintercept, linetype=Lines), cutoff, color = "blue") +
  geom_hline(aes(yintercept=yintercept, linetype=Lines), cutoff2, color = "darkgreen") +
  geom_hline(aes(yintercept=yintercept, linetype=Lines), cutoff3, color = "darkblue") + 
  labs(caption = "Note: Adult Buck Count totals 2688 and is not included on the graph")  



```


<br>
<br>

### Determine whether current harvest/check station activity allows Vermont to meet surveillance goals when samples are distributed at the county level

*If we get data from Vermont:*
We use data from the 2022 harvest for individuals sampled at biological check stations. Each individual is classified into a strata (adult male, adult female, yearling male, and yearling female), season (first weekend of regular or youth hunt), and classified into wildlife management unit (WMU).  

*If we don't get data from Vermont and use simulated data:*
We use values from the Vermont 2022 Deer Harvest report to estimate counts of individuals in strata (adult male, adult female, yearling male, and yearling female), harvested in Vermontâ€™s 14 counties, across harvest seasons (archery, youth, novice, October muzzle, regular, and December muzzle). We use an multinomial with probability informed by percentage breakdowns in the deer harvest report to estimate the count of each strata in a county by season. Vermont only collects samples from check stations from the first weekend of the regular season and from the youth hunt. We estimate that checked individuals from the regular season were only 1/3 of the total harvest. Our dataset only includes individuals harvested in the youth hunt and one-third of individuals harvested in the regular season. 
<br>

With these data, we calculate the number of samples needed to detect CWD at a given prevalence and statistical assurance (alpha). Alpha is the confidence that population-level CWD prevalence is at or below the threshold level. 


Under a simplified random sample (SRS), the confidence level heavily influences the number of samples needed and associated costs. 

Here, we divide the total number of samples needed for specific combinations of confidence and prevalence proportionally by county and then identify whether the number of samples available at a county level is enough to meet the proportional allocation. The proportional number of samples needed per county is based on the proportion of harvest. We can get the sample size we need for all counties except under one sample design scenario where we are trying to detect a small amount of the disease with high confidence (alpha of .01 and prevalence of .001)
*We no longer have a prevalence of .001 so there are no cases where we don't have enough samples. Keep?*

```{r, echo=FALSE, message = F, warning = F, fig.cap="Figure 2. Number of Samples per County", fig.width=10, fig.height=11}
SRS_for_dfs_func <- function(Indiv_county_ALL){

  Indiv_county_ALL_SRS <- Indiv_county_ALL %>% 
      #Figure out proportional harvest per country 
  mutate(prop = ContyTotal/(sum(Indiv_county_ALL$ContyTotal)))
    
  ### Create vectors of alpha and prevalence 
vecalpha <- c(.01, .05, .1, .2) #99, 95, 90, 80
vecprev <- c(seq(.01, .1, by = .0001))

## Do alpha 
Acolfunc <- function(df, n){
      varname <- paste0("alpha.", n)
      df %>%
         mutate(!!varname := 1 * n) ### Fining a way to add row of the same value 
}
Indiv_county_ALL_alph <- Indiv_county_ALL_SRS
for(i in vecalpha){
    Indiv_county_ALL_alph <- Acolfunc(df = Indiv_county_ALL_alph, n = i)
}
Indiv_county_ALL_alph <- Indiv_county_ALL_alph %>% pivot_longer(cols = starts_with("alpha"),
             names_to = "Alpha", values_to = "Alpha_level")
             

## Set up prev 
Prevcolfunc <- function(df, n){
      varname <- paste0("Prevalence", n)
      df %>%
         mutate(!!varname := 1 * n)
}
Indiv_county_ALL_Prev <- Indiv_county_ALL_SRS
for(i in vecprev){
    Indiv_county_ALL_Prev <- Prevcolfunc(df = Indiv_county_ALL_Prev, n = i)
}
Indiv_county_ALL_Prev <- Indiv_county_ALL_Prev %>% pivot_longer(cols = starts_with("Prevalence"),
             names_to = "Prevalence", values_to = "Prevalence_level")

LongAlph_Prev <- Indiv_county_ALL_Prev %>% full_join(Indiv_county_ALL_alph, 
  by = c("County","AdultBuckCount","AdultDoeCount","MaleFawnCount","FemaleFawnCount",
         "ContyTotal","Indiana","Michigan","Ohio", "prop"))


Indiv_county_ALL_SRS <- LongAlph_Prev %>% 
  ### Now calc number of samples needed 
  mutate(NoSamples = log(-((1-Alpha_level) - 1))/(log(1 - Prevalence_level))) %>% 
  mutate(NoSamplesperCounty = NoSamples*prop) %>% #mult by proportion of harvest
  ## Now calculate costs
  mutate(Cost_Indiana = NoSamplesperCounty *Indiana) %>% 
  mutate(Cost_Michigan = NoSamplesperCounty *Michigan) %>% 
  mutate(Cost_Ohio = NoSamplesperCounty *Ohio) %>% 
  ## Do we have enough samples in the county (Y/N)
  mutate(TargetMeet = if_else((NoSamplesperCounty - ContyTotal)  > 0, "False", "True"))
}

Indiv_county_CheckStations_SRS <- SRS_for_dfs_func(Indiv_county_CheckStations)

#ggplot(Indiv_county_CheckStations_SRS) + 
#  geom_point(aes(x = Prevalence_level, y = NoSamplesperCounty, color = TargetMeet))+
#  facet_wrap(~County) + 
#   labs(x = "Prevalence", y = "No. Samples per County") 

## Old graph to see if could meet target, not informative when it's all true... 

Indiv_county_CheckStations_SRS <- Indiv_county_CheckStations_SRS %>% 
  mutate(county_prev = 1- (Alpha_level^(1/NoSamplesperCounty))) %>% 
  mutate(Confidence_num = (1 - Alpha_level) *100) %>%  #create confidence label
  mutate(Confidence = paste0(Confidence_num, "%", " confidence"))

ggplot(Indiv_county_CheckStations_SRS) + 
  geom_point(aes(x = Prevalence_level, y = county_prev, color = County))+
  facet_wrap(~Confidence) + 
   labs(x = "State Wide Prevelance", y = "County Level Prevelence Achieved") 

```




Graph to add: state wide prevalence (x) vs county level prevalence (y) 
*Still not sure about this graph, see below...*
```{r}

```



### Estimating Prevalence from the Available Samples

For each county, we can take the total number of samples that are available and calculate the total prevalence that could be detected in that county if we were to use all available samples. 
```{r, echo=FALSE}
Prev_Indiv_county_CheckStations <- Indiv_county_CheckStations %>% 
  mutate(Alpha_01 = .01) %>% 
  mutate(Alpha_05 = .05) %>% 
  mutate(Alpha_1 = .1) %>% 
  pivot_longer(cols = c("Alpha_01", "Alpha_05", "Alpha_1"), 
               names_to = "Alpha", values_to = "Alpha_level") %>% 
  ### Now calc prev from number of samples 
  # extra step to make sure not too wonky 
  mutate(confidencecalc = 1 - Alpha_level) %>% 
  mutate(EstPrev = 1 - (Alpha_level)^(1/ContyTotal) )

### How are prevalence values still so high? 

## Set up table
Prev_Indiv_county_CheckStations_tbl <- Prev_Indiv_county_CheckStations %>% 
  select(County, ContyTotal, confidencecalc, EstPrev )

#colnames(Prev_Indiv_county_CheckStations_tbl) <- c("County", "No. Samples", "Confidence Level", "Prevalence")

#kable(Prev_Indiv_county_CheckStations_tbl,
#      caption = "Table 9. Total Prevalence that for a Set Level of Alpha Given the Total Number of Samples #in a County for the Check Stations Dataset",
#      align = "lrrr") %>% 
#  kable_styling(bootstrap_options = "striped")

ggplot(Prev_Indiv_county_CheckStations_tbl) + 
  geom_point(aes(x = EstPrev, y = factor(County), color = factor(confidencecalc))) + 
  labs(x = "County Level Prevalence", y = "County", color = "Confidence Level")

```


